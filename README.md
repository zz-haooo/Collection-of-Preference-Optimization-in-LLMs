# Preference-Optimization-in-LLMs

A collection of Preference-Optimization methods in LLMs.



## Collection of LLMs Survey
<table class="tg">
<thead>
  <tr>
    <th class="tg-nrix" align="center" rowspan="2">Category</th>
    <th class="tg-baqh" align="center" rowspan="2">Method</th>
    <th class="tg-baqh" align="center" rowspan="2">Title</th>
    <th class="tg-0lax" align="center" rowspan="2">Venue</th>
    <th class="tg-baqh" align="center" rowspan="2">Release Date</th>
    <th class="tg-0lax" align="center" rowspan="2">Links</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-nrix" align="center" rowspan="17">Offline</td>
    <td class="tg-0lax" align="center">DPO</td>
    <td class="tg-baqh" align="center">Direct preference optimization: Your language model is secretly a reward model</td>
    <td class="tg-0lax" align="center">NeurIPS 2023</td>
    <td class="tg-baqh" align="center">29 May 2023</td>
    <td class="tg-0lax" align="center"><a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/a85b405ed65c6477a4fe8302b5e06ce7-Paper-Conference.pdf">Paper</a></td>
  </tr>
  <tr>
    <td class="tg-0lax" align="center">PRO</td>
    <td class="tg-baqh" align="center">Preference ranking optimization for human alignment</td>
    <td class="tg-0lax" align="center">AAAI 2024</td>
    <td class="tg-baqh" align="center">30 Jun 2023</td>
    <td class="tg-0lax" align="center"><a href="https://arxiv.org/pdf/2306.17492v2">Paper</a></td>
  </tr>
  <tr>
    <td class="tg-0lax" align="center">IPO</td>
    <td class="tg-baqh" align="center">A general theoretical paradigm to understand learning from human preferences</td>
    <td class="tg-0lax" align="center">AISTATS 2024</td>
    <td class="tg-baqh" align="center">18 Oct 2023</td>
    <td class="tg-0lax" align="center"><a href="https://proceedings.mlr.press/v238/gheshlaghi-azar24a/gheshlaghi-azar24a.pdf">Paper</a></td>
  </tr>
  <tr>
    <td class="tg-0lax" align="center">CPO</td>
    <td class="tg-baqh" align="center">Contrastive preference optimization: Pushing the boundaries of llm performance in machine translation</td>
    <td class="tg-0lax" align="center">arxiv</td>
    <td class="tg-baqh" align="center">16 Jan 2024</td>
    <td class="tg-0lax" align="center"><a href="https://arxiv.org/pdf/2401.08417">Paper</a></td>
  </tr>
  
