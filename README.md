# Preference-Optimization-in-LLMs

A collection of Preference-Optimization methods in LLMs.



## Collection of LLMs Survey
<table class="tg">
<thead>
  <tr>
    <th class="tg-nrix" align="center" rowspan="2">Category</th>
    <th class="tg-baqh" align="center" rowspan="2">Method</th>
    <th class="tg-baqh" align="center" rowspan="2">Title</th>
    <th class="tg-0lax" align="center" rowspan="2">Venue</th>
    <th class="tg-baqh" align="center" rowspan="2">Release Date</th>
    <th class="tg-0lax" align="center" rowspan="2">Links</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-nrix" align="center" rowspan="17">Offline</td>
    <td class="tg-0lax" align="center">DPO</td>
    <td class="tg-baqh" align="center">Direct preference optimization: Your language model is secretly a reward model</td>
    <td class="tg-0lax" align="center">NeurIPS 2023</td>
    <td class="tg-baqh" align="center">29 May 2023</td>
    <td class="tg-0lax" align="center"><a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/a85b405ed65c6477a4fe8302b5e06ce7-Paper-Conference.pdf">Paper</a></td>
  </tr>
  <tr>
    <td class="tg-baqh" align="center">Language Model Behavior: A Comprehensive Survey</td>
    <td class="tg-0lax" align="center">arXiv</td>
    <td class="tg-baqh" align="center">20 Mar 2023</td>
    <td class="tg-0lax" align="center"><a href="https://arxiv.org/abs/2303.11504">Paper</a></td>
  </tr>
